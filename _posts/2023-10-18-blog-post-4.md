---
title: "Summary of Fully Convolutional Networks for Semantic Segmentation"
excerpt: " 
The paper discusses Fully Convolutional Networks for Semantic Segmentation by Jonathan Long, Evan Shelhamer, and Trevor Darrell from UC Berkeley. The authors introduce fully convolutional networks (FCNs) as a powerful approach for semantic segmentation, surpassing existing methods in pixel-wise prediction. The key innovation is to replace fully-connected layers with convolutional layers, allowing for end-to-end training and efficient inference on arbitrary-sized inputs. The FCN architecture incorporates both deep, coarse semantic information and shallow, fine appearance information for accurate segmentations. The paper reviews related work, emphasizes the efficiency of fully convolutional training over patchwise methods, and demonstrates state-of-the-art results on various datasets. The authors compare their approach to adaptations of deep classification nets for semantic segmentation, highlighting the end-to-end learning capability of FCNs.
<br/><img src='/images/FCN.png'>"
---


The paper discusses "Fully Convolutional Networks for Semantic Segmentation" by Jonathan Long, Evan Shelhamer, and Trevor Darrell from UC Berkeley. The authors introduce fully convolutional networks (FCNs) as a powerful approach for semantic segmentation, surpassing existing methods in pixel-wise prediction. The key innovation is to replace fully-connected layers with convolutional layers, allowing for end-to-end training and efficient inference on arbitrary-sized inputs. The FCN architecture incorporates both deep, coarse semantic information and shallow, fine appearance information for accurate segmentations. The paper reviews related work, emphasizes the efficiency of fully convolutional training over patchwise methods, and demonstrates state-of-the-art results on various datasets. The authors compare their approach to adaptations of deep classification nets for semantic segmentation, highlighting the end-to-end learning capability of FCNs.

## 1. Fully convolutional networks
Certainly! Here's the passage formatted in Markdown:

The passage discusses the architecture of Fully Convolutional Networks (FCNs) in the context of convolutional neural networks (convnets). Each layer in a convnet is represented as a three-dimensional array:

$$  h \times w \times d  $$


Here, *h* and *w* are spatial dimensions, and *d* is the feature or channel dimension. The first layer represents the image, with a pixel size of *h \times w* and *d* color channels. Locations in higher layers correspond to the locations in the image they are path-connected to, referred to as their receptive fields.

Convolutional operations in FCNs are defined as:

$$ y_{i,j} = f_{ks} \left(\{x_{si+\delta i, sj+\delta j} \mid 0 \leq \delta i, \delta j \leq k\}\right) $$

where:
- *k* is the kernel size,
- *s* is the stride or subsampling factor,
- $f_{ks}$  determines the layer type (e.g., matrix multiplication for convolution or average pooling, spatial max for max pooling, etc.).

The passage emphasizes the importance of this functional form being maintained under composition. A net with only layers of this form is referred to as a fully convolutional network (FCN), capable of operating on inputs of any size and producing outputs with corresponding spatial dimensions.

The real-valued loss function $\( \mathcal{L} \)$ composed with an FCN is defined as:

$$ \mathcal{L}(x; \theta) = \sum_{i,j} \ell \left(x_{i,j}; \theta\right) $$



where *l* is the loss function for a spatial component. The gradient of $\( \mathcal{L} \)$ is a sum over the gradients of each spatial component.

Efficiency is highlighted when feedforward computation and backpropagation are computed layer-by-layer over an entire image, particularly when receptive fields overlap significantly:


$$ f_{k,s} \circ g_{k',s'} = (f \circ g)_{k'+(k-1)s', ss'} $$


In conclusion, the passage introduces the concept of FCNs, their flexibility in handling inputs of varying sizes, and their efficiency in computation, emphasizing their application in tasks such as pixel-wise prediction.

