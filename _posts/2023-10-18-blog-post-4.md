---
title: "Summary of Fully Convolutional Networks for Semantic Segmentation"
excerpt: " 
The paper discusses Fully Convolutional Networks for Semantic Segmentation by Jonathan Long, Evan Shelhamer, and Trevor Darrell from UC Berkeley. The authors introduce fully convolutional networks (FCNs) as a powerful approach for semantic segmentation, surpassing existing methods in pixel-wise prediction. The key innovation is to replace fully-connected layers with convolutional layers, allowing for end-to-end training and efficient inference on arbitrary-sized inputs. The FCN architecture incorporates both deep, coarse semantic information and shallow, fine appearance information for accurate segmentations. The paper reviews related work, emphasizes the efficiency of fully convolutional training over patchwise methods, and demonstrates state-of-the-art results on various datasets. The authors compare their approach to adaptations of deep classification nets for semantic segmentation, highlighting the end-to-end learning capability of FCNs.
<br/><img src='/images/FCN.png'>"
---


The paper discusses "Fully Convolutional Networks for Semantic Segmentation" by Jonathan Long, Evan Shelhamer, and Trevor Darrell from UC Berkeley. The authors introduce fully convolutional networks (FCNs) as a powerful approach for semantic segmentation, surpassing existing methods in pixel-wise prediction. The key innovation is to replace fully-connected layers with convolutional layers, allowing for end-to-end training and efficient inference on arbitrary-sized inputs. The FCN architecture incorporates both deep, coarse semantic information and shallow, fine appearance information for accurate segmentations. The paper reviews related work, emphasizes the efficiency of fully convolutional training over patchwise methods, and demonstrates state-of-the-art results on various datasets. The authors compare their approach to adaptations of deep classification nets for semantic segmentation, highlighting the end-to-end learning capability of FCNs.

## 1. Fully convolutional networks
Certainly! Here's the passage formatted in Markdown:

The passage discusses the architecture of Fully Convolutional Networks (FCNs) in the context of convolutional neural networks (convnets). Each layer in a convnet is represented as a three-dimensional array:

$$  h \times w \times d  $$


Here, *h* and *w* are spatial dimensions, and *d* is the feature or channel dimension. The first layer represents the image, with a pixel size of *h \times w* and *d* color channels. Locations in higher layers correspond to the locations in the image they are path-connected to, referred to as their receptive fields.

Convolutional operations in FCNs are defined as:

$$ y_{i,j} = f_{ks} \left(\{x_{si+\delta i, sj+\delta j} \mid 0 \leq \delta i, \delta j \leq k\}\right) $$

where:
- *k* is the kernel size,
- *s* is the stride or subsampling factor,
- $f_{ks}$  determines the layer type (e.g., matrix multiplication for convolution or average pooling, spatial max for max pooling, etc.).

The passage emphasizes the importance of this functional form being maintained under composition. A net with only layers of this form is referred to as a fully convolutional network (FCN), capable of operating on inputs of any size and producing outputs with corresponding spatial dimensions.

The real-valued loss function $\( \mathcal{L} \)$ composed with an FCN is defined as:

$$ \mathcal{L}(x; \theta) = \sum_{i,j} \ell \left(x_{i,j}; \theta\right) $$



where *l* is the loss function for a spatial component. The gradient of $\( \mathcal{L} \)$ is a sum over the gradients of each spatial component.

Efficiency is highlighted when feedforward computation and backpropagation are computed layer-by-layer over an entire image, particularly when receptive fields overlap significantly:


$$ f_{k,s} \circ g_{k',s'} = (f \circ g)_{k'+(k-1)s', ss'} $$


### 1.1 Adapting classifiers for dense prediction

<img src="/images/FCN2.png" alt="alt text" height="400" />

Figure 2, Transforming fully connected layers into convolution layers enables a classification net to output a heatmap.

The passage discusses the adaptation of typical recognition networks, such as LeNet, AlexNet, and their successors, for dense prediction tasks. The fully connected layers in these networks, originally designed for fixed-sized inputs, can be viewed as convolutions covering their entire input regions. This transformation turns them into fully convolutional networks capable of taking inputs of any size and producing classification maps.

The illustration in Figure 2 depicts the convolutionalization process, showing how fully connected layers can output heatmaps. This adaptation allows classification nets to efficiently produce dense predictions. The computational efficiency is highlighted by comparing the processing times of the original net and its fully convolutional version.

The spatial output maps generated by convolutionalized models make them suitable for dense problems like semantic segmentation. The availability of ground truth at every output cell facilitates both forward and backward passes, taking advantage of the inherent computational efficiency of convolutions.

Although the reinterpretation of classification nets as fully convolutional enables output maps for inputs of any size, the output dimensions are typically reduced through subsampling. This subsampling is employed to keep filters small and manage computational requirements, resulting in a coarser output compared to the input size.

